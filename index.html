<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Shunyu Yao â€“ å§šé¡ºå®‡</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <div class="container">
        <header>
            <h1 class="name">Shunyu Yao</h1>
            <p class="subtitle">å§šé¡ºå®‡</p>
            <div class="header-controls">
                <div class="social-links">
                    <a href="mailto:ysy2017@sjtu.edu.cn" title="Email">ğŸ“§</a>
                    <a href="https://www.onestory.art" target="_blank" title="OneStory">ğŸ¬</a>
                </div>
                <div class="language-switch">
                    <button id="lang-btn" onclick="toggleLanguage()">
                        <span id="lang-text">EN</span>
                    </button>
                </div>
            </div>
        </header>

        <main>
            <!-- ä¸­æ–‡ç‰ˆæœ¬ -->
            <div id="content-zh" class="content-section active">
                <section class="about">
                    <h2>æˆ‘çš„ç®€ä»‹</h2>
                    <p>æˆ‘æ˜¯ä¸€å AIGC ç ”ç©¶è€…å’Œäº§å“è´Ÿè´£äººã€‚</p>
                    <p>æˆ‘ä¸“æ³¨äº AI é©±åŠ¨çš„å†…å®¹åˆ›ä½œã€æ•°å­—äººæŠ€æœ¯å’ŒAgentic AIç ”ç©¶ã€‚</p>
                </section>

                <section class="opinions">
                    <h2>æˆ‘çš„è§‚ç‚¹</h2>
                    <div class="links">
                        <a href="https://www.bilibili.com/video/BV1Y1ymBAE5k/?share_source=copy_web&vd_source=547cd2cb29e354bd4959722bbf7010e3" target="_blank">å¯¹è°ˆ360å‘¨é¸¿ç¥ï¼ŒAI+å†…å®¹èµ›é“çš„æœªæ¥</a>
                    </div>
                </section>

                <section class="selected-work">
                    <h2>æˆ‘çš„å·¥ä½œ</h2>

                    <div class="work-item">
                        <h3>OneStory</h3>
                        <p class="affiliation">åˆ›å£¹ç§‘æŠ€</p>
                        <p class="description">é¢å‘å‚ç±»åˆ›ä½œè€…çš„ AI åŸç”Ÿè§†è§‰å™äº‹å¹³å°ï¼ŒæœåŠ¡å¯¼æ¼”ã€åˆ†é•œå¸ˆå’Œå†…å®¹åˆ›ä½œè€…ã€‚æ„å»ºä»åˆ›æ„åˆ°è„šæœ¬ã€åˆ†é•œã€è§†é¢‘çš„å®Œæ•´ AI åˆ›ä½œæµç¨‹ã€‚</p>
                        <div class="links">
                            <a href="https://global.onestory.art" target="_blank">æµ·å¤–ç‰ˆäº§å“</a> | 
                            <a href="https://www.onestory.art" target="_blank">å›½å†…ç‰ˆäº§å“</a>
                        </div>
                    </div>

                    <div class="work-item">
                        <h3>AIGC å†…å®¹åˆ›ä½œé¡¹ç›®</h3>
                        <p class="affiliation">åˆ›å£¹ç§‘æŠ€</p>
                        <p class="description">äº§å‡ºå¤šéƒ¨ç™¾ä¸‡çº§åŠåƒä¸‡çº§æ’­æ”¾é‡çš„ AIGC çˆ†æ¬¾è§†é¢‘ï¼Œå±•ç¤º AI é©±åŠ¨çš„å™äº‹èƒ½åŠ›å’Œè§’è‰²åŠ¨ç”»æŠ€æœ¯ã€‚</p>
                        <div class="video-links">
                            <a href="https://v.douyin.com/bm6CUjA-BXY/" target="_blank">æå¹¼æ–Œè·¨æ—¶ç©ºå¯¹è¯æäº‘é¾™</a> | 
                            <a href="https://v.douyin.com/7wI0ypsYzAw/" target="_blank">å·¥å‚åœ°çƒ</a> | 
                            <a href="https://v.douyin.com/-iWs04uF6Pg/" target="_blank">AIç‰ˆæŸ³å¤œç†™å›å½’</a>
                        </div>
                    </div>

                    <div class="work-item">
                        <h3>å¤šè§’è‰²ä¸€è‡´æ€§çš„åŒºåŸŸæ³¨æ„åŠ›æœºåˆ¶</h3>
                        <p class="affiliation">åˆ›å£¹ç§‘æŠ€</p>
                        <p class="description">æå‡ºæ–°é¢–çš„æ–¹æ³•ç”¨äºå¤šè§’è‰²å›¾åƒç”Ÿæˆä¸­çš„è§’è‰²ä¸€è‡´æ€§ä¿æŒå’Œç©ºé—´æ§åˆ¶ï¼Œå®ç°å•å¼ å›¾åƒä¸­çš„å¤š LoRA æ³¨å…¥ã€‚</p>
                        <div class="links">
                            <a href="https://arxiv.org/abs/2508.00477">è®ºæ–‡ï¼ˆAAAI 2026 å®¡ç¨¿ä¸­ï¼‰</a>
                        </div>
                    </div>

                    <div class="work-item">
                        <h3>Voka å…¨èº«åŠ¨æ•ç›´æ’­è½¯ä»¶</h3>
                        <p class="affiliation">æˆ‘å’–ç§‘æŠ€</p>
                        <p class="description">ä½¿ç”¨æ™®é€šæ‘„åƒå¤´è¿›è¡Œé¢éƒ¨ã€æ‰‹éƒ¨å’Œèº«ä½“åŠ¨ä½œæ•æ‰çš„å®æ—¶è™šæ‹Ÿç›´æ’­è½¯ä»¶ï¼Œå·²éƒ¨ç½²åœ¨ PC å’Œç§»åŠ¨ç«¯å¹³å°ã€‚</p>
                        <div class="links">
                            <a href="https://pan.quark.cn/s/cddbaf0b31c4">è§†é¢‘demo</a>
                        </div>
                    </div>

                    <div class="work-item">
                        <h3>åŸºäº NeRF çš„è¶…å†™å®æ•°å­—äºº</h3>
                        <p class="affiliation">æˆ‘å’–ç§‘æŠ€</p>
                        <p class="description">ä½¿ç”¨ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰å’Œ GAN æŠ€æœ¯å®ç°è¯­éŸ³é©±åŠ¨çš„è¶…å†™å®æ•°å­—äººç”Ÿæˆã€‚</p>
                        <div class="links">
                            <a href="https://arxiv.org/abs/2201.00791">è®ºæ–‡</a>
                        </div>
                    </div>
                </section>

                <section class="publications">
                    <h2>è®ºæ–‡å‘è¡¨</h2>

                    <div class="pub-item">
                        <p class="pub-title">LAMIC: Layout-Aware Multi-Image Composition via Scalability of Multimodal Diffusion Transformer</p>
                        <p class="pub-authors">Yuzhuo Chen, Zehua Ma, Jianhua Wang, Kai Kang, <strong>Shunyu Yao</strong>, Weiming Zhang</p>
                        <p class="pub-venue">arXiv é¢„å°æœ¬ 2025ï¼ˆé€šè®¯ä½œè€…ï¼‰</p>
                        <div class="links">
                            <a href="https://arxiv.org/abs/2508.00477" target="_blank">è®ºæ–‡</a> |
                            <a href="https://github.com/Suchenl/LAMIC" target="_blank">ä»£ç </a>
                        </div>
                    </div>

                    <div class="pub-item">
                        <p class="pub-title">DialogueNeRF: Towards Realistic Avatar Face-to-face Conversation Video Generation</p>
                        <p class="pub-authors">Zanwei Zhou, Zi Wang, <strong>Shunyu Yao</strong>, et al.</p>
                        <p class="pub-venue">arXiv é¢„å°æœ¬ 2022</p>
                        <div class="links">
                            <a href="https://arxiv.org/abs/2203.07931" target="_blank">è®ºæ–‡</a>
                        </div>
                    </div>

                    <div class="pub-item">
                        <p class="pub-title">DFA-NeRF: Personalized Talking Head Generation via Disentangled Face Attributes Neural Rendering</p>
                        <p class="pub-authors"><strong>Shunyu Yao</strong>, et al.</p>
                        <p class="pub-venue">arXiv é¢„å°æœ¬ 2022</p>
                        <div class="links">
                            <a href="https://arxiv.org/abs/2201.00791" target="_blank">è®ºæ–‡</a> | 
                            <a href="https://github.com/ShunyuYao/DFA-NeRF" target="_blank">ä»£ç </a>
                        </div>
                    </div>

                    <div class="pub-item">
                        <p class="pub-title">Poxture: Human Posture Imitation Using Neural Texture</p>
                        <p class="pub-authors">Yang Chen, <strong>Shunyu Yao</strong>, et al.</p>
                        <p class="pub-venue">IEEE Transactions on Circuits and Systems for Video Technology 2022</p>
                        <div class="links">
                            <a href="https://ieeexplore.ieee.org/document/9829868" target="_blank">è®ºæ–‡</a>
                        </div>
                    </div>

                    <div class="pub-item">
                        <p class="pub-title">Deep Audio-Visual Fusion Neural Network for Saliency Estimation</p>
                        <p class="pub-authors"><strong>Shunyu Yao</strong>, Xiongkuo Min, Guangtao Zhai</p>
                        <p class="pub-venue">IEEE International Conference on Image Processing (ICIP) 2021</p>
                        <div class="links">
                            <a href="https://ieeexplore.ieee.org/document/9506089" target="_blank">è®ºæ–‡</a>
                        </div>
                    </div>

                    <div class="pub-item">
                        <p class="pub-title">HPOF: 3D Human Pose Recovery from Monocular Video with Optical Flow</p>
                        <p class="pub-authors">Ji Bin, Yang Chen, <strong>Shunyu Yao</strong>, et al.</p>
                        <p class="pub-venue">International Conference on Multimedia Retrieval (ICMR) 2021</p>
                        <div class="links">
                            <a href="https://dl.acm.org/doi/10.1145/3460426.3463605" target="_blank">è®ºæ–‡</a>
                        </div>
                    </div>
                </section>

                <section class="awards">
                    <h2>è·å¥–è£èª‰</h2>
                    <ul>
                        <li>2024 åä¸ºæ˜‡è…¾ AI åˆ›æ–°å¤§èµ›æ¹–å—èµ›åŒºå† å†›ï¼ˆåˆ›å£¹ç§‘æŠ€ï¼‰</li>
                        <li>2020 ä¸Šæµ·å¸‚æœ€å…·æŠ•èµ„æ½œåŠ› 50 ä½³åˆ›ä¸šä¼ä¸šï¼ˆæˆ‘å’–ç§‘æŠ€ï¼‰</li>
                        <li>2020 æ·±åœ³å¸‚æœ€å…·æŠ•èµ„ä»·å€¼å›¢é˜Ÿï¼ˆæˆ‘å’–ç§‘æŠ€ï¼‰</li>
                        <li>2019 äº’è”ç½‘+åˆ›æ–°åˆ›ä¸šå¤§èµ›é“¶å¥–</li>
                        <li>2019 ç¬¬å››å±Š"åˆ›æ±‡é’æ˜¥"å›½é™…èµ›ä¸€ç­‰å¥–</li>
                        <li>2019 OPPO TOP é«˜æ ¡åˆ›æ–°æŒ‘æˆ˜èµ› THE BEST å¥–</li>
                        <li>2018 åä¸º ICT åˆ›æ–°å¤§èµ›ä¸€ç­‰å¥–</li>
                    </ul>
                </section>

                <section class="education">
                    <h2>æ•™è‚²èƒŒæ™¯</h2>
                    <ul>
                        <li><strong>ä¸Šæµ·äº¤é€šå¤§å­¦</strong> - ä¿¡æ¯ä¸é€šä¿¡å·¥ç¨‹åšå£«ï¼ˆ2020-2024ï¼‰</li>
                        <li><strong>ä¸Šæµ·äº¤é€šå¤§å­¦</strong> - ä»ªå™¨ç§‘å­¦ä¸å·¥ç¨‹ç¡•å£«ï¼ˆ2017-2020ï¼‰</li>
                        <li><strong>è¥¿å®‰äº¤é€šå¤§å­¦</strong> - æœºæ¢°å·¥ç¨‹åŠè‡ªåŠ¨åŒ–å­¦å£«ï¼ˆ2012-2016ï¼‰</li>
                    </ul>
                </section>
            </div>

            <!-- è‹±æ–‡ç‰ˆæœ¬ -->
            <div id="content-en" class="content-section">
                <section class="about">
                    <h2>About</h2>
                    <p>I am an AIGC researcher and product leader.</p>
                    <p>I study AI-powered content creation, digital humans, and multi-agent systems.</p>
                </section>

                <section class="selected-work">
                    <h2>Selected Work</h2>

                    <div class="work-item">
                        <h3>OneStory</h3>
                        <p class="affiliation">Chuangyi Technology</p>
                        <p class="description">An AI-native platform for visual storytelling, serving directors, storyboard artists, and content creators. Building the complete AI pipeline from creative ideas to scripts, storyboards, and videos.</p>
                        <div class="links">
                            <a href="https://global.onestory.art" target="_blank">Global</a> | 
                            <a href="https://www.onestory.art" target="_blank">China</a>
                        </div>
                        <div class="achievements">
                            <p>â€¢ 250K+ registered users in one year</p>
                            <p>â€¢ Revenue exceeds compute costs</p>
                            <p>â€¢ Reduced production costs by 30% for Liu Yexi IP</p>
                        </div>
                    </div>

                    <div class="work-item">
                        <h3>AI Content Creation Projects</h3>
                        <p class="affiliation">Chuangyi Technology</p>
                        <p class="description">Multiple viral AIGC videos with millions of views, showcasing AI-powered storytelling and character animation.</p>
                        <div class="video-links">
                            <a href="https://v.douyin.com/bm6CUjA-BXY/" target="_blank">Li Youbin's Cross-Time Dialogue (12M+ views)</a> | 
                            <a href="https://v.douyin.com/7wI0ypsYzAw/" target="_blank">Factory Earth (7.6M+ views)</a> | 
                            <a href="https://v.douyin.com/-iWs04uF6Pg/" target="_blank">AI Liu Yexi Returns (1M+ views)</a>
                        </div>
                    </div>

                    <div class="work-item">
                        <h3>Region Attention for Multi-Character Consistency</h3>
                        <p class="affiliation">Chuangyi Technology</p>
                        <p class="description">A novel approach for maintaining character consistency and spatial control in multi-character image generation, enabling multiple LoRA injection in a single image.</p>
                        <div class="links">
                            <a href="#">paper (AAAI 2026 under review)</a>
                        </div>
                    </div>

                    <div class="work-item">
                        <h3>Voka Full-Body Motion Capture Software</h3>
                        <p class="affiliation">Voka Technology</p>
                        <p class="description">Real-time virtual streaming software using ordinary cameras for face, hand, and body motion capture. Deployed on PC and mobile platforms.</p>
                        <div class="links">
                            <a href="#">product</a>
                        </div>
                    </div>

                    <div class="work-item">
                        <h3>NeRF-based Photorealistic Digital Human</h3>
                        <p class="affiliation">Voka Technology</p>
                        <p class="description">Audio-driven photorealistic digital human generation using Neural Radiance Fields (NeRF) and GANs.</p>
                        <div class="links">
                            <a href="#">paper</a>
                        </div>
                    </div>
                </section>

                <section class="opinions">
                    <h2>My Views</h2>
                    <div class="links">
                        <a href="https://www.bilibili.com/video/BV1Y1ymBAE5k/?share_source=copy_web&vd_source=547cd2cb29e354bd4959722bbf7010e3" target="_blank">Discussion with 360 Zhou Hongyi: The Future of AI + Content</a>
                    </div>
                </section>

                <section class="publications">
                    <h2>Publications</h2>

                    <div class="pub-item">
                        <p class="pub-title">LAMIC: Layout-Aware Multi-Image Composition via Scalability of Multimodal Diffusion Transformer</p>
                        <p class="pub-authors">Yuzhuo Chen, Zehua Ma, Jianhua Wang, Kai Kang, <strong>Shunyu Yao</strong>, Weiming Zhang</p>
                        <p class="pub-venue">arXiv preprint 2025 (Corresponding author)</p>
                        <div class="links">
                            <a href="https://arxiv.org/abs/2508.00477" target="_blank">paper</a> | 
                            <a href="https://github.com/Suchenl/LAMIC" target="_blank">code</a>
                        </div>
                    </div>

                    <div class="pub-item">
                        <p class="pub-title">DialogueNeRF: Towards Realistic Avatar Face-to-face Conversation Video Generation</p>
                        <p class="pub-authors">Zanwei Zhou, Zi Wang, <strong>Shunyu Yao</strong>, et al.</p>
                        <p class="pub-venue">arXiv preprint 2022</p>
                        <div class="links">
                            <a href="https://arxiv.org/abs/2203.07931" target="_blank">paper</a>
                        </div>
                    </div>

                    <div class="pub-item">
                        <p class="pub-title">DFA-NeRF: Personalized Talking Head Generation via Disentangled Face Attributes Neural Rendering</p>
                        <p class="pub-authors"><strong>Shunyu Yao</strong>, et al.</p>
                        <p class="pub-venue">arXiv preprint 2022</p>
                        <div class="links">
                            <a href="https://arxiv.org/abs/2201.00791" target="_blank">paper</a> | 
                            <a href="https://github.com/ShunyuYao/DFA-NeRF" target="_blank">code</a>
                        </div>
                    </div>

                    <div class="pub-item">
                        <p class="pub-title">Poxture: Human Posture Imitation Using Neural Texture</p>
                        <p class="pub-authors">Yang Chen, <strong>Shunyu Yao</strong>, et al.</p>
                        <p class="pub-venue">IEEE Transactions on Circuits and Systems for Video Technology 2022</p>
                        <div class="links">
                            <a href="https://ieeexplore.ieee.org/document/9829868" target="_blank">paper</a>
                        </div>
                    </div>

                    <div class="pub-item">
                        <p class="pub-title">Deep Audio-Visual Fusion Neural Network for Saliency Estimation</p>
                        <p class="pub-authors"><strong>Shunyu Yao</strong>, Xiongkuo Min, and Guangtao Zhai</p>
                        <p class="pub-venue">IEEE International Conference on Image Processing (ICIP) 2021</p>
                        <div class="links">
                            <a href="https://ieeexplore.ieee.org/document/9506089" target="_blank">paper</a>
                        </div>
                    </div>

                    <div class="pub-item">
                        <p class="pub-title">HPOF: 3D Human Pose Recovery from Monocular Video with Optical Flow</p>
                        <p class="pub-authors">Ji Bin, Yang Chen, <strong>Shunyu Yao</strong>, et al.</p>
                        <p class="pub-venue">International Conference on Multimedia Retrieval (ICMR) 2021</p>
                        <div class="links">
                            <a href="https://dl.acm.org/doi/10.1145/3460426.3463605" target="_blank">paper</a>
                        </div>
                    </div>
                </section>

                <section class="awards">
                    <h2>Awards & Honors</h2>
                    <ul>
                        <li>2024 Huawei Ascend AI Innovation Competition - Hunan Regional Champion (Chuangyi Technology)</li>
                        <li>2020 Shanghai Top 50 Most Investment-Worthy Startups (Voka Technology)</li>
                        <li>2020 Shenzhen Most Investment-Worthy Team (Voka Technology)</li>
                        <li>2019 Internet+ Innovation and Entrepreneurship Competition - Silver Award</li>
                        <li>2019 4th "Chuanghui Youth" International Competition - First Prize</li>
                        <li>2019 OPPO TOP Campus Innovation Challenge - THE BEST Award</li>
                        <li>2018 Huawei ICT Innovation Competition - First Prize</li>
                    </ul>
                </section>

                <section class="education">
                    <h2>Education</h2>
                    <ul>
                        <li><strong>Shanghai Jiao Tong University</strong> - PhD in Information and Communication Engineering (2020-2024)</li>
                        <li><strong>Shanghai Jiao Tong University</strong> - M.S. in Instrument Science and Engineering (2017-2020)</li>
                        <li><strong>Xi'an Jiaotong University</strong> - B.S. in Mechanical Engineering and Automation (2012-2016)</li>
                    </ul>
                </section>
            </div>
        </main>

        <footer>
            <p id="footer-text">(æœ€åæ›´æ–°ï¼š2025å¹´10æœˆ)</p>
        </footer>
    </div>

    <script>
        // é»˜è®¤è¯­è¨€ä¸ºä¸­æ–‡
        let currentLang = 'zh';

        // ä» localStorage è¯»å–ç”¨æˆ·ä¸Šæ¬¡é€‰æ‹©çš„è¯­è¨€
        if (localStorage.getItem('preferredLang')) {
            currentLang = localStorage.getItem('preferredLang');
            if (currentLang === 'en') {
                switchToEnglish();
            }
        }

        function toggleLanguage() {
            if (currentLang === 'zh') {
                switchToEnglish();
            } else {
                switchToChinese();
            }
        }

        function switchToEnglish() {
            currentLang = 'en';
            document.getElementById('content-zh').classList.remove('active');
            document.getElementById('content-en').classList.add('active');
            document.getElementById('lang-text').textContent = 'ä¸­æ–‡';
            document.getElementById('footer-text').textContent = '(last updated: October 2025)';
            document.documentElement.lang = 'en';
            localStorage.setItem('preferredLang', 'en');
        }

        function switchToChinese() {
            currentLang = 'zh';
            document.getElementById('content-en').classList.remove('active');
            document.getElementById('content-zh').classList.add('active');
            document.getElementById('lang-text').textContent = 'EN';
            document.getElementById('footer-text').textContent = '(æœ€åæ›´æ–°ï¼š2025å¹´10æœˆ)';
            document.documentElement.lang = 'zh-CN';
            localStorage.setItem('preferredLang', 'zh');
        }
    </script>
</body>
</html>

